{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "bs = 100\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byunghunhwang/dev/flame-ssd-model/venv/lib/python3.11/site-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim, c_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim + c_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim + c_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "    \n",
    "    def encoder(self, x, c):\n",
    "        concat_input = torch.cat([x, c], 1)\n",
    "        h = F.relu(self.fc1(concat_input))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h)\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add(mu) # return z sample\n",
    "    \n",
    "    def decoder(self, z, c):\n",
    "        concat_input = torch.cat([z, c], 1)\n",
    "        h = F.relu(self.fc4(concat_input))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h))\n",
    "    \n",
    "    def forward(self, x, c):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784), c)\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z, c), mu, log_var\n",
    "\n",
    "# build model\n",
    "cond_dim = train_loader.dataset.train_labels.unique().size(0)\n",
    "cvae = CVAE(x_dim=784, h_dim1=512, h_dim2=256, z_dim=2, c_dim=cond_dim)\n",
    "if torch.cuda.is_available():\n",
    "    cvae.cuda()\n",
    "else:\n",
    "    cvae.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(cvae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# one-hot encoding\n",
    "def one_hot(labels, class_size): \n",
    "    targets = torch.zeros(labels.size(0), class_size)\n",
    "    for i, label in enumerate(labels):\n",
    "        targets[i, label] = 1\n",
    "    return Variable(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    cvae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, cond) in enumerate(train_loader):\n",
    "        data, cond = data.cpu(), one_hot(cond, cond_dim).cpu()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = cvae(data, cond)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    cvae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, cond in test_loader:\n",
    "            data, cond = data.cpu(), one_hot(cond, cond_dim).cpu()\n",
    "            recon, mu, log_var = cvae(data, cond)\n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 544.341758\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 179.631191\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 155.215039\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 156.621416\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 149.539707\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 143.808545\n",
      "====> Epoch: 1 Average loss: 163.0279\n",
      "====> Test set loss: 141.2406\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 154.150830\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 140.032090\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 141.778740\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 140.141094\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 136.568398\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 137.433770\n",
      "====> Epoch: 2 Average loss: 138.6727\n",
      "====> Test set loss: 136.4407\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 133.293779\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 133.753838\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 134.501328\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 133.338652\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 134.263496\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 124.874131\n",
      "====> Epoch: 3 Average loss: 135.2023\n",
      "====> Test set loss: 134.3055\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 123.245430\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 132.888066\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 131.924434\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 133.337148\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 133.468320\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 131.320400\n",
      "====> Epoch: 4 Average loss: 133.3862\n",
      "====> Test set loss: 132.9888\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 142.716309\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 135.638525\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 134.732178\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 142.002012\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 133.962559\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 128.283496\n",
      "====> Epoch: 5 Average loss: 132.2443\n",
      "====> Test set loss: 132.3728\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 128.203184\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 122.314199\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 134.722412\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 132.835615\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 131.006084\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 135.050771\n",
      "====> Epoch: 6 Average loss: 131.5124\n",
      "====> Test set loss: 131.5844\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 130.764639\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 136.679521\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 125.847334\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 127.404795\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 137.704854\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 131.739707\n",
      "====> Epoch: 7 Average loss: 130.9127\n",
      "====> Test set loss: 131.3181\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 128.863604\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 129.114727\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 130.099229\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 130.930439\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 123.783750\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 127.198555\n",
      "====> Epoch: 8 Average loss: 130.3921\n",
      "====> Test set loss: 131.0257\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 134.022725\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 132.096992\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 129.015605\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 129.169717\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 134.060059\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 128.025830\n",
      "====> Epoch: 9 Average loss: 130.0031\n",
      "====> Test set loss: 130.5555\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 132.700723\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 123.116875\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 130.774795\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 128.890381\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 125.086064\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 134.267930\n",
      "====> Epoch: 10 Average loss: 129.5875\n",
      "====> Test set loss: 130.2431\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 136.991729\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 136.665215\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 132.638320\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 133.610938\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 132.291758\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 126.295107\n",
      "====> Epoch: 11 Average loss: 129.2508\n",
      "====> Test set loss: 130.2992\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 126.898096\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 122.416426\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 135.035322\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 136.904043\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 127.612520\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 121.311299\n",
      "====> Epoch: 12 Average loss: 128.9104\n",
      "====> Test set loss: 129.7923\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 136.401563\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 129.941660\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 118.453506\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 121.181523\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 133.907354\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 127.239746\n",
      "====> Epoch: 13 Average loss: 128.6571\n",
      "====> Test set loss: 129.5972\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 126.414297\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 131.554053\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 136.261777\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 129.713623\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 119.363984\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 127.975078\n",
      "====> Epoch: 14 Average loss: 128.4202\n",
      "====> Test set loss: 129.5172\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 131.140176\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 133.027529\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 125.114912\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 121.577168\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 128.009492\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 125.265693\n",
      "====> Epoch: 15 Average loss: 128.1275\n",
      "====> Test set loss: 129.4118\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 125.268701\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 129.784785\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 126.157275\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 125.837051\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 132.560059\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 131.508936\n",
      "====> Epoch: 16 Average loss: 127.8190\n",
      "====> Test set loss: 129.2364\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 130.670791\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 126.419912\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 122.685527\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 127.137803\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 130.667949\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 128.737373\n",
      "====> Epoch: 17 Average loss: 127.6523\n",
      "====> Test set loss: 128.9852\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 121.565215\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 134.203926\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 127.664844\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 126.192275\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 121.425371\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 120.076270\n",
      "====> Epoch: 18 Average loss: 127.4254\n",
      "====> Test set loss: 128.9572\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 126.201113\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 122.085381\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 128.991934\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 126.990244\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 120.073037\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 132.766270\n",
      "====> Epoch: 19 Average loss: 127.2050\n",
      "====> Test set loss: 128.8969\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 118.889414\n",
      "Train Epoch: 20 [10000/60000 (17%)]\tLoss: 125.268545\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 130.958604\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 120.953779\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 123.253955\n",
      "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 126.990605\n",
      "====> Epoch: 20 Average loss: 126.9518\n",
      "====> Test set loss: 128.9735\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 122.132275\n",
      "Train Epoch: 21 [10000/60000 (17%)]\tLoss: 126.764736\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 120.248965\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 129.846309\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 116.595283\n",
      "Train Epoch: 21 [50000/60000 (83%)]\tLoss: 127.334932\n",
      "====> Epoch: 21 Average loss: 126.8498\n",
      "====> Test set loss: 128.5617\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 130.592158\n",
      "Train Epoch: 22 [10000/60000 (17%)]\tLoss: 126.326094\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 119.930537\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 128.357461\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 132.013125\n",
      "Train Epoch: 22 [50000/60000 (83%)]\tLoss: 125.469463\n",
      "====> Epoch: 22 Average loss: 126.5656\n",
      "====> Test set loss: 128.7914\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 121.029883\n",
      "Train Epoch: 23 [10000/60000 (17%)]\tLoss: 130.079336\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 125.465010\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 129.865127\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 132.317822\n",
      "Train Epoch: 23 [50000/60000 (83%)]\tLoss: 128.226328\n",
      "====> Epoch: 23 Average loss: 126.4237\n",
      "====> Test set loss: 128.4549\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 121.788525\n",
      "Train Epoch: 24 [10000/60000 (17%)]\tLoss: 126.472041\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 122.429912\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 122.708350\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 127.198164\n",
      "Train Epoch: 24 [50000/60000 (83%)]\tLoss: 119.590107\n",
      "====> Epoch: 24 Average loss: 126.2464\n",
      "====> Test set loss: 128.4857\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 124.102383\n",
      "Train Epoch: 25 [10000/60000 (17%)]\tLoss: 128.822451\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 127.936846\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 129.953838\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 118.636201\n",
      "Train Epoch: 25 [50000/60000 (83%)]\tLoss: 128.309297\n",
      "====> Epoch: 25 Average loss: 126.1344\n",
      "====> Test set loss: 128.3295\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 121.320527\n",
      "Train Epoch: 26 [10000/60000 (17%)]\tLoss: 125.065215\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 131.880918\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 131.941904\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 125.744023\n",
      "Train Epoch: 26 [50000/60000 (83%)]\tLoss: 126.970127\n",
      "====> Epoch: 26 Average loss: 125.8979\n",
      "====> Test set loss: 128.4197\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 127.864746\n",
      "Train Epoch: 27 [10000/60000 (17%)]\tLoss: 122.411240\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 122.265518\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 128.305586\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 130.847627\n",
      "Train Epoch: 27 [50000/60000 (83%)]\tLoss: 124.620000\n",
      "====> Epoch: 27 Average loss: 125.6756\n",
      "====> Test set loss: 128.1692\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 128.342246\n",
      "Train Epoch: 28 [10000/60000 (17%)]\tLoss: 134.995605\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 122.582012\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 124.970430\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 127.711230\n",
      "Train Epoch: 28 [50000/60000 (83%)]\tLoss: 126.956865\n",
      "====> Epoch: 28 Average loss: 125.5127\n",
      "====> Test set loss: 128.3920\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 128.161006\n",
      "Train Epoch: 29 [10000/60000 (17%)]\tLoss: 122.839268\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 121.803115\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 126.114102\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 129.522354\n",
      "Train Epoch: 29 [50000/60000 (83%)]\tLoss: 125.779443\n",
      "====> Epoch: 29 Average loss: 125.4298\n",
      "====> Test set loss: 128.1460\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 119.820049\n",
      "Train Epoch: 30 [10000/60000 (17%)]\tLoss: 123.947217\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 119.815156\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 124.966377\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 130.957881\n",
      "Train Epoch: 30 [50000/60000 (83%)]\tLoss: 121.161191\n",
      "====> Epoch: 30 Average loss: 125.2957\n",
      "====> Test set loss: 127.9639\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 120.323252\n",
      "Train Epoch: 31 [10000/60000 (17%)]\tLoss: 123.474424\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 123.141455\n",
      "Train Epoch: 31 [30000/60000 (50%)]\tLoss: 122.748350\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 120.263096\n",
      "Train Epoch: 31 [50000/60000 (83%)]\tLoss: 123.325264\n",
      "====> Epoch: 31 Average loss: 125.1644\n",
      "====> Test set loss: 128.1304\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 124.034248\n",
      "Train Epoch: 32 [10000/60000 (17%)]\tLoss: 121.285352\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 128.777041\n",
      "Train Epoch: 32 [30000/60000 (50%)]\tLoss: 121.883115\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 125.496387\n",
      "Train Epoch: 32 [50000/60000 (83%)]\tLoss: 124.552773\n",
      "====> Epoch: 32 Average loss: 125.0698\n",
      "====> Test set loss: 128.3553\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 119.187305\n",
      "Train Epoch: 33 [10000/60000 (17%)]\tLoss: 128.306221\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 127.881152\n",
      "Train Epoch: 33 [30000/60000 (50%)]\tLoss: 118.924805\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 129.503379\n",
      "Train Epoch: 33 [50000/60000 (83%)]\tLoss: 118.409541\n",
      "====> Epoch: 33 Average loss: 124.8481\n",
      "====> Test set loss: 128.1774\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 127.094531\n",
      "Train Epoch: 34 [10000/60000 (17%)]\tLoss: 132.535928\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 122.720605\n",
      "Train Epoch: 34 [30000/60000 (50%)]\tLoss: 121.862578\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 122.898330\n",
      "Train Epoch: 34 [50000/60000 (83%)]\tLoss: 117.201211\n",
      "====> Epoch: 34 Average loss: 124.7993\n",
      "====> Test set loss: 128.1527\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 130.244307\n",
      "Train Epoch: 35 [10000/60000 (17%)]\tLoss: 120.518047\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 125.758730\n",
      "Train Epoch: 35 [30000/60000 (50%)]\tLoss: 123.229619\n",
      "Train Epoch: 35 [40000/60000 (67%)]\tLoss: 119.406631\n",
      "Train Epoch: 35 [50000/60000 (83%)]\tLoss: 128.514082\n",
      "====> Epoch: 35 Average loss: 124.5894\n",
      "====> Test set loss: 128.0559\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 130.646465\n",
      "Train Epoch: 36 [10000/60000 (17%)]\tLoss: 129.162402\n",
      "Train Epoch: 36 [20000/60000 (33%)]\tLoss: 125.922568\n",
      "Train Epoch: 36 [30000/60000 (50%)]\tLoss: 126.767813\n",
      "Train Epoch: 36 [40000/60000 (67%)]\tLoss: 126.483564\n",
      "Train Epoch: 36 [50000/60000 (83%)]\tLoss: 124.554199\n",
      "====> Epoch: 36 Average loss: 124.4616\n",
      "====> Test set loss: 128.1563\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 122.825615\n",
      "Train Epoch: 37 [10000/60000 (17%)]\tLoss: 118.542852\n",
      "Train Epoch: 37 [20000/60000 (33%)]\tLoss: 120.756641\n",
      "Train Epoch: 37 [30000/60000 (50%)]\tLoss: 126.497793\n",
      "Train Epoch: 37 [40000/60000 (67%)]\tLoss: 134.182578\n",
      "Train Epoch: 37 [50000/60000 (83%)]\tLoss: 127.003730\n",
      "====> Epoch: 37 Average loss: 124.3192\n",
      "====> Test set loss: 127.7957\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 122.591699\n",
      "Train Epoch: 38 [10000/60000 (17%)]\tLoss: 116.974482\n",
      "Train Epoch: 38 [20000/60000 (33%)]\tLoss: 125.754922\n",
      "Train Epoch: 38 [30000/60000 (50%)]\tLoss: 126.248398\n",
      "Train Epoch: 38 [40000/60000 (67%)]\tLoss: 121.490391\n",
      "Train Epoch: 38 [50000/60000 (83%)]\tLoss: 125.774785\n",
      "====> Epoch: 38 Average loss: 124.1969\n",
      "====> Test set loss: 127.8624\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 129.415508\n",
      "Train Epoch: 39 [10000/60000 (17%)]\tLoss: 126.297549\n",
      "Train Epoch: 39 [20000/60000 (33%)]\tLoss: 126.217568\n",
      "Train Epoch: 39 [30000/60000 (50%)]\tLoss: 116.096621\n",
      "Train Epoch: 39 [40000/60000 (67%)]\tLoss: 121.022373\n",
      "Train Epoch: 39 [50000/60000 (83%)]\tLoss: 120.970986\n",
      "====> Epoch: 39 Average loss: 124.1134\n",
      "====> Test set loss: 128.1042\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 122.840400\n",
      "Train Epoch: 40 [10000/60000 (17%)]\tLoss: 120.501465\n",
      "Train Epoch: 40 [20000/60000 (33%)]\tLoss: 120.982002\n",
      "Train Epoch: 40 [30000/60000 (50%)]\tLoss: 117.659424\n",
      "Train Epoch: 40 [40000/60000 (67%)]\tLoss: 125.855830\n",
      "Train Epoch: 40 [50000/60000 (83%)]\tLoss: 127.053555\n",
      "====> Epoch: 40 Average loss: 124.0793\n",
      "====> Test set loss: 127.9570\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 122.176367\n",
      "Train Epoch: 41 [10000/60000 (17%)]\tLoss: 123.426416\n",
      "Train Epoch: 41 [20000/60000 (33%)]\tLoss: 118.900762\n",
      "Train Epoch: 41 [30000/60000 (50%)]\tLoss: 125.368984\n",
      "Train Epoch: 41 [40000/60000 (67%)]\tLoss: 124.183555\n",
      "Train Epoch: 41 [50000/60000 (83%)]\tLoss: 123.004941\n",
      "====> Epoch: 41 Average loss: 123.9382\n",
      "====> Test set loss: 128.0138\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 130.617236\n",
      "Train Epoch: 42 [10000/60000 (17%)]\tLoss: 125.535840\n",
      "Train Epoch: 42 [20000/60000 (33%)]\tLoss: 125.785039\n",
      "Train Epoch: 42 [30000/60000 (50%)]\tLoss: 122.391670\n",
      "Train Epoch: 42 [40000/60000 (67%)]\tLoss: 124.238311\n",
      "Train Epoch: 42 [50000/60000 (83%)]\tLoss: 130.207646\n",
      "====> Epoch: 42 Average loss: 123.7988\n",
      "====> Test set loss: 127.7678\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 123.090225\n",
      "Train Epoch: 43 [10000/60000 (17%)]\tLoss: 123.929629\n",
      "Train Epoch: 43 [20000/60000 (33%)]\tLoss: 120.018096\n",
      "Train Epoch: 43 [30000/60000 (50%)]\tLoss: 120.953574\n",
      "Train Epoch: 43 [40000/60000 (67%)]\tLoss: 133.527402\n",
      "Train Epoch: 43 [50000/60000 (83%)]\tLoss: 120.852881\n",
      "====> Epoch: 43 Average loss: 123.6947\n",
      "====> Test set loss: 127.5602\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 123.639287\n",
      "Train Epoch: 44 [10000/60000 (17%)]\tLoss: 117.003564\n",
      "Train Epoch: 44 [20000/60000 (33%)]\tLoss: 116.711240\n",
      "Train Epoch: 44 [30000/60000 (50%)]\tLoss: 124.465010\n",
      "Train Epoch: 44 [40000/60000 (67%)]\tLoss: 125.045332\n",
      "Train Epoch: 44 [50000/60000 (83%)]\tLoss: 121.722451\n",
      "====> Epoch: 44 Average loss: 123.4980\n",
      "====> Test set loss: 127.6749\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 126.106729\n",
      "Train Epoch: 45 [10000/60000 (17%)]\tLoss: 122.847031\n",
      "Train Epoch: 45 [20000/60000 (33%)]\tLoss: 122.399746\n",
      "Train Epoch: 45 [30000/60000 (50%)]\tLoss: 123.603662\n",
      "Train Epoch: 45 [40000/60000 (67%)]\tLoss: 121.706367\n",
      "Train Epoch: 45 [50000/60000 (83%)]\tLoss: 122.494229\n",
      "====> Epoch: 45 Average loss: 123.4159\n",
      "====> Test set loss: 127.7071\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 124.397012\n",
      "Train Epoch: 46 [10000/60000 (17%)]\tLoss: 126.460977\n",
      "Train Epoch: 46 [20000/60000 (33%)]\tLoss: 125.733838\n",
      "Train Epoch: 46 [30000/60000 (50%)]\tLoss: 127.183262\n",
      "Train Epoch: 46 [40000/60000 (67%)]\tLoss: 119.001299\n",
      "Train Epoch: 46 [50000/60000 (83%)]\tLoss: 121.038789\n",
      "====> Epoch: 46 Average loss: 123.4041\n",
      "====> Test set loss: 128.0275\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 127.998984\n",
      "Train Epoch: 47 [10000/60000 (17%)]\tLoss: 124.804395\n",
      "Train Epoch: 47 [20000/60000 (33%)]\tLoss: 122.717910\n",
      "Train Epoch: 47 [30000/60000 (50%)]\tLoss: 114.395684\n",
      "Train Epoch: 47 [40000/60000 (67%)]\tLoss: 121.569639\n",
      "Train Epoch: 47 [50000/60000 (83%)]\tLoss: 114.893896\n",
      "====> Epoch: 47 Average loss: 123.2727\n",
      "====> Test set loss: 127.8938\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 123.732949\n",
      "Train Epoch: 48 [10000/60000 (17%)]\tLoss: 111.056250\n",
      "Train Epoch: 48 [20000/60000 (33%)]\tLoss: 120.292939\n",
      "Train Epoch: 48 [30000/60000 (50%)]\tLoss: 122.102832\n",
      "Train Epoch: 48 [40000/60000 (67%)]\tLoss: 121.322383\n",
      "Train Epoch: 48 [50000/60000 (83%)]\tLoss: 123.895771\n",
      "====> Epoch: 48 Average loss: 123.1325\n",
      "====> Test set loss: 127.9195\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 116.196807\n",
      "Train Epoch: 49 [10000/60000 (17%)]\tLoss: 127.476025\n",
      "Train Epoch: 49 [20000/60000 (33%)]\tLoss: 120.083154\n",
      "Train Epoch: 49 [30000/60000 (50%)]\tLoss: 115.543389\n",
      "Train Epoch: 49 [40000/60000 (67%)]\tLoss: 127.122412\n",
      "Train Epoch: 49 [50000/60000 (83%)]\tLoss: 121.701895\n",
      "====> Epoch: 49 Average loss: 123.1047\n",
      "====> Test set loss: 128.0287\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 121.534238\n",
      "Train Epoch: 50 [10000/60000 (17%)]\tLoss: 125.632490\n",
      "Train Epoch: 50 [20000/60000 (33%)]\tLoss: 119.422715\n",
      "Train Epoch: 50 [30000/60000 (50%)]\tLoss: 123.680625\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 131.382842\n",
      "Train Epoch: 50 [50000/60000 (83%)]\tLoss: 126.747744\n",
      "====> Epoch: 50 Average loss: 123.0343\n",
      "====> Test set loss: 127.9440\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(1, 51):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # z = torch.randn(10, 2).cuda()\n",
    "    # c = torch.eye(10).cuda()\n",
    "    z = torch.randn(10, 2).cpu()\n",
    "    c = torch.eye(10).cpu()\n",
    "    \n",
    "\n",
    "    sample = cvae.decoder(z, c)\n",
    "    save_image(sample.view(10, 1, 28, 28), './samples/sample_' + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
