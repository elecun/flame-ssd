{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "bs = 100\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "vae.cpu()\n",
    "# if torch.cuda.is_available():\n",
    "#     vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        #data = data.cuda()\n",
    "        data = data.cpu()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            #data = data.cuda()\n",
    "            data = data.cpu()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 543.514453\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 185.244961\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 162.233604\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 175.613574\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 163.437715\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 158.294814\n",
      "====> Epoch: 1 Average loss: 177.4350\n",
      "====> Test set loss: 161.4401\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 165.477715\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 154.977637\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 159.362559\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 148.159238\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 156.305469\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 159.765352\n",
      "====> Epoch: 2 Average loss: 157.5057\n",
      "====> Test set loss: 155.0734\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 154.650254\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 157.232295\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 162.249395\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 149.327012\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 156.282549\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 158.408877\n",
      "====> Epoch: 3 Average loss: 153.1018\n",
      "====> Test set loss: 152.4266\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 149.030156\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 150.109980\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 149.953350\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 153.031895\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 153.584805\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 154.861084\n",
      "====> Epoch: 4 Average loss: 150.4937\n",
      "====> Test set loss: 150.1937\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 140.462109\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 145.361641\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 140.020068\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 154.332480\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 145.449980\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 143.955166\n",
      "====> Epoch: 5 Average loss: 148.5787\n",
      "====> Test set loss: 148.5272\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 150.808525\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 145.759668\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 146.339600\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 151.596211\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 151.647188\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 145.239072\n",
      "====> Epoch: 6 Average loss: 147.3341\n",
      "====> Test set loss: 147.4360\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 146.197070\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 145.683242\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 147.937070\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 148.821504\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 145.644014\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 141.644404\n",
      "====> Epoch: 7 Average loss: 146.1942\n",
      "====> Test set loss: 146.0771\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 143.635615\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 143.245430\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 142.619150\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 144.911709\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 148.971084\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 149.278193\n",
      "====> Epoch: 8 Average loss: 145.1626\n",
      "====> Test set loss: 146.0887\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 150.716758\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 144.964775\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 141.658818\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 141.701670\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 144.939238\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 153.681367\n",
      "====> Epoch: 9 Average loss: 144.4933\n",
      "====> Test set loss: 144.9532\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 145.674697\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 144.327285\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 142.272393\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 149.131299\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 145.642920\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 138.941582\n",
      "====> Epoch: 10 Average loss: 143.6066\n",
      "====> Test set loss: 144.3564\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 145.936660\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 138.982139\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 146.324912\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 141.639385\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 137.309932\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 148.317627\n",
      "====> Epoch: 11 Average loss: 142.9905\n",
      "====> Test set loss: 144.0081\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 140.515645\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 150.148223\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 142.309863\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 146.144814\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 142.243408\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 140.402402\n",
      "====> Epoch: 12 Average loss: 142.5840\n",
      "====> Test set loss: 143.2675\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 140.574990\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 143.219941\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 141.470684\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 133.664893\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 136.937637\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 145.382695\n",
      "====> Epoch: 13 Average loss: 142.1521\n",
      "====> Test set loss: 142.9834\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 147.466943\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 142.885449\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 136.959355\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 137.773594\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 144.953965\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 141.255859\n",
      "====> Epoch: 14 Average loss: 141.7092\n",
      "====> Test set loss: 143.0130\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 122.867822\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 144.687988\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 129.988828\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 142.104316\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 145.290371\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 140.503350\n",
      "====> Epoch: 15 Average loss: 141.2096\n",
      "====> Test set loss: 142.6878\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 143.798154\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 134.066172\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 135.345371\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 145.724092\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 151.256748\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 137.467949\n",
      "====> Epoch: 16 Average loss: 141.1217\n",
      "====> Test set loss: 142.0399\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 144.003125\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 135.139980\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 150.486436\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 137.755742\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 134.968936\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 144.064131\n",
      "====> Epoch: 17 Average loss: 140.6869\n",
      "====> Test set loss: 142.1733\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 136.689121\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 144.683154\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 138.362354\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 133.550674\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 143.579111\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 137.224678\n",
      "====> Epoch: 18 Average loss: 140.3178\n",
      "====> Test set loss: 141.8132\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 138.329199\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 130.896338\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 149.486846\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 137.927998\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 152.842451\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 132.684717\n",
      "====> Epoch: 19 Average loss: 140.2851\n",
      "====> Test set loss: 141.5530\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 135.041553\n",
      "Train Epoch: 20 [10000/60000 (17%)]\tLoss: 135.263164\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 147.020420\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 145.657012\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 136.836260\n",
      "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 136.764941\n",
      "====> Epoch: 20 Average loss: 140.4840\n",
      "====> Test set loss: 142.0067\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 138.486777\n",
      "Train Epoch: 21 [10000/60000 (17%)]\tLoss: 139.524014\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 133.092588\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 140.222070\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 139.245508\n",
      "Train Epoch: 21 [50000/60000 (83%)]\tLoss: 140.161641\n",
      "====> Epoch: 21 Average loss: 140.0168\n",
      "====> Test set loss: 141.5038\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 143.360811\n",
      "Train Epoch: 22 [10000/60000 (17%)]\tLoss: 145.767285\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 142.200791\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 145.251406\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 135.758262\n",
      "Train Epoch: 22 [50000/60000 (83%)]\tLoss: 141.918262\n",
      "====> Epoch: 22 Average loss: 140.0322\n",
      "====> Test set loss: 141.2564\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 141.154580\n",
      "Train Epoch: 23 [10000/60000 (17%)]\tLoss: 145.987324\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 137.691689\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 137.979863\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 132.543496\n",
      "Train Epoch: 23 [50000/60000 (83%)]\tLoss: 142.927822\n",
      "====> Epoch: 23 Average loss: 139.4728\n",
      "====> Test set loss: 140.3473\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 129.718535\n",
      "Train Epoch: 24 [10000/60000 (17%)]\tLoss: 129.566250\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 138.529199\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 143.038457\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 131.728320\n",
      "Train Epoch: 24 [50000/60000 (83%)]\tLoss: 133.737363\n",
      "====> Epoch: 24 Average loss: 139.3020\n",
      "====> Test set loss: 140.4017\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 144.541797\n",
      "Train Epoch: 25 [10000/60000 (17%)]\tLoss: 143.414844\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 134.228379\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 138.139990\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 139.800654\n",
      "Train Epoch: 25 [50000/60000 (83%)]\tLoss: 137.419541\n",
      "====> Epoch: 25 Average loss: 138.7952\n",
      "====> Test set loss: 140.2019\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 139.089404\n",
      "Train Epoch: 26 [10000/60000 (17%)]\tLoss: 145.846045\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 144.077969\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 142.834326\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 133.427656\n",
      "Train Epoch: 26 [50000/60000 (83%)]\tLoss: 137.231191\n",
      "====> Epoch: 26 Average loss: 138.6195\n",
      "====> Test set loss: 140.2752\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 134.041367\n",
      "Train Epoch: 27 [10000/60000 (17%)]\tLoss: 131.501133\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 143.951875\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 139.715303\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 131.745967\n",
      "Train Epoch: 27 [50000/60000 (83%)]\tLoss: 135.130352\n",
      "====> Epoch: 27 Average loss: 138.6413\n",
      "====> Test set loss: 140.2022\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 134.651982\n",
      "Train Epoch: 28 [10000/60000 (17%)]\tLoss: 138.714375\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 146.460830\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 146.715850\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 144.098252\n",
      "Train Epoch: 28 [50000/60000 (83%)]\tLoss: 143.372686\n",
      "====> Epoch: 28 Average loss: 138.5019\n",
      "====> Test set loss: 139.9566\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 135.722578\n",
      "Train Epoch: 29 [10000/60000 (17%)]\tLoss: 133.330791\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 141.152051\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 141.075166\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 138.101230\n",
      "Train Epoch: 29 [50000/60000 (83%)]\tLoss: 136.241797\n",
      "====> Epoch: 29 Average loss: 138.0276\n",
      "====> Test set loss: 140.3211\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 137.824805\n",
      "Train Epoch: 30 [10000/60000 (17%)]\tLoss: 134.844512\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 139.474883\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 135.412402\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 135.181982\n",
      "Train Epoch: 30 [50000/60000 (83%)]\tLoss: 144.070820\n",
      "====> Epoch: 30 Average loss: 138.2566\n",
      "====> Test set loss: 140.6588\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 127.506953\n",
      "Train Epoch: 31 [10000/60000 (17%)]\tLoss: 139.532412\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 140.944521\n",
      "Train Epoch: 31 [30000/60000 (50%)]\tLoss: 140.052051\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 142.852324\n",
      "Train Epoch: 31 [50000/60000 (83%)]\tLoss: 134.804932\n",
      "====> Epoch: 31 Average loss: 137.9030\n",
      "====> Test set loss: 139.8718\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 131.951006\n",
      "Train Epoch: 32 [10000/60000 (17%)]\tLoss: 135.128252\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 141.603936\n",
      "Train Epoch: 32 [30000/60000 (50%)]\tLoss: 136.224883\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 136.465137\n",
      "Train Epoch: 32 [50000/60000 (83%)]\tLoss: 132.364111\n",
      "====> Epoch: 32 Average loss: 137.8377\n",
      "====> Test set loss: 139.9452\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 145.363037\n",
      "Train Epoch: 33 [10000/60000 (17%)]\tLoss: 132.898223\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 145.722910\n",
      "Train Epoch: 33 [30000/60000 (50%)]\tLoss: 132.081172\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 134.452305\n",
      "Train Epoch: 33 [50000/60000 (83%)]\tLoss: 148.016758\n",
      "====> Epoch: 33 Average loss: 137.8902\n",
      "====> Test set loss: 140.0093\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 136.947061\n",
      "Train Epoch: 34 [10000/60000 (17%)]\tLoss: 148.754863\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 134.451846\n",
      "Train Epoch: 34 [30000/60000 (50%)]\tLoss: 138.007480\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 140.898438\n",
      "Train Epoch: 34 [50000/60000 (83%)]\tLoss: 139.475283\n",
      "====> Epoch: 34 Average loss: 137.7922\n",
      "====> Test set loss: 139.7467\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 136.603545\n",
      "Train Epoch: 35 [10000/60000 (17%)]\tLoss: 140.650078\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 132.323418\n",
      "Train Epoch: 35 [30000/60000 (50%)]\tLoss: 141.750586\n",
      "Train Epoch: 35 [40000/60000 (67%)]\tLoss: 138.291533\n",
      "Train Epoch: 35 [50000/60000 (83%)]\tLoss: 135.468516\n",
      "====> Epoch: 35 Average loss: 137.9034\n",
      "====> Test set loss: 139.8578\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 131.435078\n",
      "Train Epoch: 36 [10000/60000 (17%)]\tLoss: 139.801123\n",
      "Train Epoch: 36 [20000/60000 (33%)]\tLoss: 132.288359\n",
      "Train Epoch: 36 [30000/60000 (50%)]\tLoss: 140.103027\n",
      "Train Epoch: 36 [40000/60000 (67%)]\tLoss: 139.690879\n",
      "Train Epoch: 36 [50000/60000 (83%)]\tLoss: 135.721426\n",
      "====> Epoch: 36 Average loss: 137.7159\n",
      "====> Test set loss: 139.8851\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 142.996582\n",
      "Train Epoch: 37 [10000/60000 (17%)]\tLoss: 131.637979\n",
      "Train Epoch: 37 [20000/60000 (33%)]\tLoss: 136.540186\n",
      "Train Epoch: 37 [30000/60000 (50%)]\tLoss: 135.489014\n",
      "Train Epoch: 37 [40000/60000 (67%)]\tLoss: 141.724189\n",
      "Train Epoch: 37 [50000/60000 (83%)]\tLoss: 130.847627\n",
      "====> Epoch: 37 Average loss: 137.5644\n",
      "====> Test set loss: 139.1337\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 135.273018\n",
      "Train Epoch: 38 [10000/60000 (17%)]\tLoss: 136.711885\n",
      "Train Epoch: 38 [20000/60000 (33%)]\tLoss: 139.169619\n",
      "Train Epoch: 38 [30000/60000 (50%)]\tLoss: 137.072451\n",
      "Train Epoch: 38 [40000/60000 (67%)]\tLoss: 132.129746\n",
      "Train Epoch: 38 [50000/60000 (83%)]\tLoss: 141.885977\n",
      "====> Epoch: 38 Average loss: 137.1210\n",
      "====> Test set loss: 139.4097\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 141.473086\n",
      "Train Epoch: 39 [10000/60000 (17%)]\tLoss: 137.429629\n",
      "Train Epoch: 39 [20000/60000 (33%)]\tLoss: 140.492979\n",
      "Train Epoch: 39 [30000/60000 (50%)]\tLoss: 130.573076\n",
      "Train Epoch: 39 [40000/60000 (67%)]\tLoss: 135.567656\n",
      "Train Epoch: 39 [50000/60000 (83%)]\tLoss: 123.108350\n",
      "====> Epoch: 39 Average loss: 137.2402\n",
      "====> Test set loss: 139.4015\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 133.094717\n",
      "Train Epoch: 40 [10000/60000 (17%)]\tLoss: 134.347090\n",
      "Train Epoch: 40 [20000/60000 (33%)]\tLoss: 131.361006\n",
      "Train Epoch: 40 [30000/60000 (50%)]\tLoss: 142.770186\n",
      "Train Epoch: 40 [40000/60000 (67%)]\tLoss: 134.917812\n",
      "Train Epoch: 40 [50000/60000 (83%)]\tLoss: 132.394570\n",
      "====> Epoch: 40 Average loss: 136.9742\n",
      "====> Test set loss: 139.4222\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 131.890791\n",
      "Train Epoch: 41 [10000/60000 (17%)]\tLoss: 134.891846\n",
      "Train Epoch: 41 [20000/60000 (33%)]\tLoss: 133.236094\n",
      "Train Epoch: 41 [30000/60000 (50%)]\tLoss: 145.392637\n",
      "Train Epoch: 41 [40000/60000 (67%)]\tLoss: 138.151387\n",
      "Train Epoch: 41 [50000/60000 (83%)]\tLoss: 137.877510\n",
      "====> Epoch: 41 Average loss: 136.9074\n",
      "====> Test set loss: 139.3726\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 137.987070\n",
      "Train Epoch: 42 [10000/60000 (17%)]\tLoss: 144.413457\n",
      "Train Epoch: 42 [20000/60000 (33%)]\tLoss: 133.164922\n",
      "Train Epoch: 42 [30000/60000 (50%)]\tLoss: 138.019268\n",
      "Train Epoch: 42 [40000/60000 (67%)]\tLoss: 135.159404\n",
      "Train Epoch: 42 [50000/60000 (83%)]\tLoss: 136.481797\n",
      "====> Epoch: 42 Average loss: 136.7371\n",
      "====> Test set loss: 139.2610\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 140.544199\n",
      "Train Epoch: 43 [10000/60000 (17%)]\tLoss: 141.076055\n",
      "Train Epoch: 43 [20000/60000 (33%)]\tLoss: 136.850986\n",
      "Train Epoch: 43 [30000/60000 (50%)]\tLoss: 137.940469\n",
      "Train Epoch: 43 [40000/60000 (67%)]\tLoss: 134.484922\n",
      "Train Epoch: 43 [50000/60000 (83%)]\tLoss: 132.716670\n",
      "====> Epoch: 43 Average loss: 136.5887\n",
      "====> Test set loss: 139.3505\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 138.167754\n",
      "Train Epoch: 44 [10000/60000 (17%)]\tLoss: 135.194004\n",
      "Train Epoch: 44 [20000/60000 (33%)]\tLoss: 140.408652\n",
      "Train Epoch: 44 [30000/60000 (50%)]\tLoss: 139.359121\n",
      "Train Epoch: 44 [40000/60000 (67%)]\tLoss: 130.240010\n",
      "Train Epoch: 44 [50000/60000 (83%)]\tLoss: 142.560186\n",
      "====> Epoch: 44 Average loss: 136.6010\n",
      "====> Test set loss: 139.6595\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 128.753945\n",
      "Train Epoch: 45 [10000/60000 (17%)]\tLoss: 136.479961\n",
      "Train Epoch: 45 [20000/60000 (33%)]\tLoss: 143.567939\n",
      "Train Epoch: 45 [30000/60000 (50%)]\tLoss: 142.925713\n",
      "Train Epoch: 45 [40000/60000 (67%)]\tLoss: 134.017100\n",
      "Train Epoch: 45 [50000/60000 (83%)]\tLoss: 136.622490\n",
      "====> Epoch: 45 Average loss: 136.3772\n",
      "====> Test set loss: 139.0613\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 135.003506\n",
      "Train Epoch: 46 [10000/60000 (17%)]\tLoss: 136.652959\n",
      "Train Epoch: 46 [20000/60000 (33%)]\tLoss: 134.815352\n",
      "Train Epoch: 46 [30000/60000 (50%)]\tLoss: 138.720215\n",
      "Train Epoch: 46 [40000/60000 (67%)]\tLoss: 134.118945\n",
      "Train Epoch: 46 [50000/60000 (83%)]\tLoss: 145.625840\n",
      "====> Epoch: 46 Average loss: 136.3259\n",
      "====> Test set loss: 138.6637\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 137.497920\n",
      "Train Epoch: 47 [10000/60000 (17%)]\tLoss: 128.317373\n",
      "Train Epoch: 47 [20000/60000 (33%)]\tLoss: 133.866963\n",
      "Train Epoch: 47 [30000/60000 (50%)]\tLoss: 139.591064\n",
      "Train Epoch: 47 [40000/60000 (67%)]\tLoss: 130.738066\n",
      "Train Epoch: 47 [50000/60000 (83%)]\tLoss: 132.381748\n",
      "====> Epoch: 47 Average loss: 136.3287\n",
      "====> Test set loss: 138.5427\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 138.022422\n",
      "Train Epoch: 48 [10000/60000 (17%)]\tLoss: 141.319570\n",
      "Train Epoch: 48 [20000/60000 (33%)]\tLoss: 136.247471\n",
      "Train Epoch: 48 [30000/60000 (50%)]\tLoss: 131.968447\n",
      "Train Epoch: 48 [40000/60000 (67%)]\tLoss: 138.825791\n",
      "Train Epoch: 48 [50000/60000 (83%)]\tLoss: 132.239961\n",
      "====> Epoch: 48 Average loss: 136.1293\n",
      "====> Test set loss: 138.9011\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 140.537295\n",
      "Train Epoch: 49 [10000/60000 (17%)]\tLoss: 141.066709\n",
      "Train Epoch: 49 [20000/60000 (33%)]\tLoss: 138.697139\n",
      "Train Epoch: 49 [30000/60000 (50%)]\tLoss: 144.592354\n",
      "Train Epoch: 49 [40000/60000 (67%)]\tLoss: 142.854268\n",
      "Train Epoch: 49 [50000/60000 (83%)]\tLoss: 134.962021\n",
      "====> Epoch: 49 Average loss: 136.0985\n",
      "====> Test set loss: 138.8563\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 143.766289\n",
      "Train Epoch: 50 [10000/60000 (17%)]\tLoss: 144.221768\n",
      "Train Epoch: 50 [20000/60000 (33%)]\tLoss: 135.876445\n",
      "Train Epoch: 50 [30000/60000 (50%)]\tLoss: 139.619648\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 138.304902\n",
      "Train Epoch: 50 [50000/60000 (83%)]\tLoss: 137.782861\n",
      "====> Epoch: 50 Average loss: 135.9556\n",
      "====> Test set loss: 138.4220\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.7314e-11, 9.8369e-11, 4.6975e-11,  ..., 6.6764e-11, 4.2264e-11,\n",
      "         4.6756e-11],\n",
      "        [1.2238e-14, 1.2214e-13, 3.6733e-14,  ..., 2.6934e-14, 1.8585e-13,\n",
      "         9.6497e-14],\n",
      "        [8.2317e-12, 1.5964e-11, 1.3177e-11,  ..., 8.6355e-12, 1.4051e-11,\n",
      "         1.3023e-11],\n",
      "        ...,\n",
      "        [4.8957e-10, 4.8266e-10, 5.8374e-10,  ..., 5.0972e-10, 4.8289e-10,\n",
      "         5.5326e-10],\n",
      "        [7.0450e-11, 5.7470e-11, 6.0710e-11,  ..., 7.0644e-11, 8.0123e-11,\n",
      "         8.2901e-11],\n",
      "        [3.6943e-13, 2.6528e-13, 3.9976e-13,  ..., 2.5179e-13, 2.6314e-13,\n",
      "         4.1184e-13]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # z = torch.randn(64, 2).cuda()\n",
    "    # sample = vae.decoder(z).cuda()\n",
    "    z = torch.randn(64, 2).cpu()\n",
    "    sample = vae.decoder(z).cpu()\n",
    "    print(sample)\n",
    "    \n",
    "    save_image(sample.view(64, 1, 28, 28), './samples/sample_' + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
